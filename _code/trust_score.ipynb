{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import torch,os\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from collections import OrderedDict\n",
    "sns.set_style('darkgrid')\n",
    "from IPython.display import display\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "- Simply load the data by inputting `dataset`, `model`, `atk` values.\n",
    "- Please Note that *tinyimagenet* has only *resnet18* + *PGD* support. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cifar10 \t Model: robust_resnet18 \t Attack: DeepFool \t Split: test \t HF: 0 \t samples: 120\n"
     ]
    }
   ],
   "source": [
    "dataset = 'cifar10' # [cifar10, svhn, tinyimagenet]\n",
    "model = 'robust_resnet18' # [resnet18, robust_resnet18, mobilenet_ddb, mobilenet_trust, mobilenet_freq, mobilenet_random, robust_wideresnet, googlenet, vgg11]\n",
    "split = 'test' # ['test', 'train']\n",
    "atk = 'DeepFool' # [DeepFool, PGD]\n",
    "samples=120\n",
    "hf = 0 # [0,1] 0 is old version and 1 is new version\n",
    "\n",
    "print(f'Dataset: {dataset} \\t Model: {model} \\t Attack: {atk} \\t Split: {split} \\t HF: {hf} \\t samples: {samples}')\n",
    "data = pd.read_csv(f'../csv_data/FAS_data/{dataset}/{model}_{split}_{atk}_{hf}.csv', index_col=False)\n",
    "df = pd.DataFrame(data)\n",
    "# len(df['Flipping_Freq'][df['Flipping_Freq'] == -1])\n",
    "df['ddbs'] = df['ddbs'].fillna(1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute T-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trust_score(ddbs: list,Flipping_Freq: list) -> list:\n",
    "    \n",
    "    def normalize_list(x:list) -> list:\n",
    "        x = np.array(x)\n",
    "        if max(x)-min(x) == 0:\n",
    "            return np.ones_like(x)\n",
    "        return (x-min(x))/(max(x)-min(x))\n",
    "    \n",
    "    norm_Flipping_Freq = normalize_list(Flipping_Freq)\n",
    "    norm_Flipping_Freq = 1-norm_Flipping_Freq\n",
    "    # print(np.max(ddbs), max(ddbs))\n",
    "    norm_ddbs = normalize_list(ddbs)\n",
    "    \n",
    "    # TScore = lambda x,y: (y+x)/2\n",
    "    TScore = lambda x,y: (2*x*y)/(x+y+1e-5)\n",
    "    # TScore = lambda x,y: (x+y)/2\n",
    "    # TScore = lambda x,y: 1/(x+1e-8) + y\n",
    " \n",
    "\n",
    "    T_score = TScore(norm_ddbs ,norm_Flipping_Freq)\n",
    "\n",
    "    return T_score, norm_ddbs, norm_Flipping_Freq\n",
    "\n",
    "T_score, norm_ddbs, norm_Flipping_Freq = get_trust_score(df['ddbs'].tolist() , df['Flipping_Freq'].tolist())\n",
    "df['T_score'] = T_score\n",
    "df['norm_ddbs'] = norm_ddbs\n",
    "df['norm_Flipping_Freq'] = norm_Flipping_Freq\n",
    "# df['T_score'] = df['T_score'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cifar10 \t Attack: DeepFool \t Model: robust_resnet18 \t split: test\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0179299acec9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK_means_flagging_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'norm_ddbs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK_means_flagging_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'norm_Flipping_Freq'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK_means_flagging_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'T_score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-c56bbe2f1b64>\u001b[0m in \u001b[0;36mK_means_flagging_recall\u001b[0;34m(df, values, r)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mK_means_flagging_recall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'flag_{values}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "def K_means_flagging(df, values,r):\n",
    "    kmeans = KMeans(n_clusters=2, random_state=r)\n",
    "    # print(np.isnan(np.array(df[values])).nonzero()) \n",
    "    df[f'flag_{values}'] = kmeans.fit_predict(np.array(df[values]).reshape(-1,1))\n",
    "    c1,c2 = kmeans.cluster_centers_\n",
    "\n",
    "    if c1< c2: df[f'flag_{values}'] = 1-df[f'flag_{values}']  ## we should flag those which are closer to smaller centroids\n",
    "\n",
    "    filter_flag_ddbs = df[(df[f'flag_{values}']) == 1]\n",
    "    total_flags = len(filter_flag_ddbs)\n",
    "    correct_flags = len(filter_flag_ddbs[(filter_flag_ddbs['Model_preds'] != filter_flag_ddbs['gt'])])\n",
    "\n",
    "    print(f'{values} \\t\\t correct_flags: {correct_flags}, total_flags: {total_flags}, %correct: {correct_flags*100/ total_flags:.2f}')\n",
    "    return df\n",
    "\n",
    "def GMM(df, values,r):\n",
    "    gmm = GaussianMixture(n_components=2, random_state = r)\n",
    "    df[f'flag_{values}'] = gmm.fit_predict(np.array(df[values]).reshape(-1,1))\n",
    "    c1,c2 = gmm.means_\n",
    "\n",
    "    if c1< c2: df[f'flag_{values}'] = 1-df[f'flag_{values}']  ## we should flag those which are closer to smaller centroids\n",
    "\n",
    "    filter_flag_ddbs = df[(df[f'flag_{values}']) == 1]\n",
    "    total_flags = len(filter_flag_ddbs)\n",
    "    correct_flags = len(filter_flag_ddbs[(filter_flag_ddbs['Model_preds'] != filter_flag_ddbs['gt'])])\n",
    "\n",
    "    print(f'{values} \\t\\t correct_flags: {correct_flags}, total_flags: {total_flags}, %correct: {correct_flags*100/ total_flags:.2f}')\n",
    "    return df\n",
    "\n",
    "print(f'Dataset: {dataset} \\t Attack: {atk} \\t Model: {model} \\t split: {split}')\n",
    "\n",
    "r = 0\n",
    "df = K_means_flagging_recall(df,'norm_ddbs',r)\n",
    "df = K_means_flagging_recall(df,'norm_Flipping_Freq',r)\n",
    "df = K_means_flagging_recall(df,'T_score',r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_t_score_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-d3e400829862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorrect_flags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_flags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_acc_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_t_score_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mobilenet_trust'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DeepFool'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_t_score_model' is not defined"
     ]
    }
   ],
   "source": [
    "correct_flags, total_flags, flag_acc_t = eval_t_score_model('resnet18','PGD', 120, seed=5, values='T_score', verbose=False)\n",
    "correct_flags, total_flags, flag_acc_t = eval_t_score_model('resnet18','PGD', 120, seed=5, values='norm_Flipping_Freq', verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do Cherrypicking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import torch,os\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from collections import OrderedDict\n",
    "sns.set_style('darkgrid')\n",
    "from IPython.display import display\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def eval_t_score_model(model,atk,seed=3, values='T_score', verbose=False, recall=False):\n",
    "    r = seed\n",
    "    dataset = 'cifar10' # [cifar10, svhn, tinyimagenet]\n",
    "    # model = 'mobilenet_trust' # [resnet18, robust_resnet18, mobilenet_ddb, mobilenet_trust, robust_wideresnet, googlenet, vgg11]\n",
    "    split = 'test' # ['test', 'train']\n",
    "    # atk = 'PGD' # [DeepFool, PGD]\n",
    "    hf = 0 # [0,1] 0 is old version and 1 is new version\n",
    "    if verbose:\n",
    "        print(f'Dataset: {dataset} \\t Model: {model} \\t Attack: {atk} \\t Split: {split} \\t HF: {hf}')\n",
    "        print('Using file: ', f'../csv_data/FAS_data/{dataset}/{model}_{split}_{atk}_{hf}.csv')\n",
    "    data = pd.read_csv(f'../csv_data/FAS_data/{dataset}/{model}_{split}_{atk}_{hf}.csv', index_col=False)\n",
    "    df = pd.DataFrame(data)\n",
    "    # len(df['Flipping_Freq'][df['Flipping_Freq'] == -1])\n",
    "\n",
    "    def get_trust_score(ddbs: list,Flipping_Freq: list) -> list:\n",
    "        \n",
    "        def normalize_list(x:list) -> list:\n",
    "            x = np.array(x)\n",
    "            if max(x)-min(x) == 0:\n",
    "                return np.ones_like(x)\n",
    "            return (x-min(x))/(max(x)-min(x))\n",
    "        \n",
    "        norm_Flipping_Freq = normalize_list(Flipping_Freq)\n",
    "        norm_Flipping_Freq = 1-norm_Flipping_Freq\n",
    "        norm_ddbs = normalize_list(ddbs)\n",
    "        \n",
    "        # TScore = lambda x,y: (y+x)/2\n",
    "        TScore = lambda x,y: (2*x*y)/(x+y+1e-5)\n",
    "        # TScore = lambda x,y: (x+y)/2\n",
    "        # TScore = lambda x,y: 1/(x+1e-8) + y\n",
    "    \n",
    "\n",
    "        T_score = TScore(norm_ddbs ,norm_Flipping_Freq)\n",
    "\n",
    "        return T_score, norm_ddbs, norm_Flipping_Freq\n",
    "\n",
    "    T_score, norm_ddbs, norm_Flipping_Freq = get_trust_score(df['ddbs'].tolist() , df['Flipping_Freq'].tolist())\n",
    "    df['T_score'] = T_score\n",
    "    df['norm_ddbs'] = norm_ddbs\n",
    "    df['norm_Flipping_Freq'] = norm_Flipping_Freq\n",
    "\n",
    "    # df['T_score'] = df['T_score'].fillna(1)\n",
    "    def K_means_flagging(df, values,r):\n",
    "        kmeans = KMeans(n_clusters=2, random_state=r)\n",
    "        df[f'flag_{values}'] = kmeans.fit_predict(np.array(df[values]).reshape(-1,1))\n",
    "        c1,c2 = kmeans.cluster_centers_\n",
    "\n",
    "        if c1< c2: df[f'flag_{values}'] = 1-df[f'flag_{values}']  ## we should flag those which are closer to smaller centroids\n",
    "\n",
    "        filter_flag_ddbs = df[(df[f'flag_{values}']) == 1]\n",
    "        total_flags = len(filter_flag_ddbs)\n",
    "        correct_flags = len(filter_flag_ddbs[(filter_flag_ddbs['Model_preds'] != filter_flag_ddbs['gt'])])\n",
    "        \n",
    "        \n",
    "        flag_acc = correct_flags*100/ total_flags\n",
    "        # print(f'{values} \\t\\t correct_flags: {correct_flags}, total_flags: {total_flags}, %correct: {flag_acc:.2f}')\n",
    "        return df, correct_flags, total_flags, flag_acc\n",
    "    \n",
    "    def K_means_flagging_recall(df, values,r):\n",
    "        kmeans = KMeans(n_clusters=2, random_state=r)\n",
    "        df[f'flag_{values}'] = kmeans.fit_predict(np.array(df[values]).reshape(-1,1))\n",
    "        c1,c2 = kmeans.cluster_centers_\n",
    "\n",
    "        if c1< c2: df[f'flag_{values}'] = 1-df[f'flag_{values}']  ## assign incorrect_cluster =1 and correct_cluster = 0 \n",
    "\n",
    "        incorrect_cluster = df[(df[f'flag_{values}']) == 1]\n",
    "        correct_cluster = df[(df[f'flag_{values}']) == 0]\n",
    "\n",
    "        total_flags = len(incorrect_cluster)\n",
    "        incorrect_pred_incorrect_cluster = len(incorrect_cluster[(incorrect_cluster['Model_preds'] != incorrect_cluster['gt'])])\n",
    "        incorrect_pred_correct_cluster = len(correct_cluster[(correct_cluster['Model_preds'] != correct_cluster['gt'])])\n",
    "        print(f'{values} \\t %Recall Val: {incorrect_pred_incorrect_cluster*100/ (incorrect_pred_incorrect_cluster + incorrect_pred_correct_cluster)}')\n",
    "        return df, None,None,None\n",
    "       \n",
    "        \n",
    "        # recall = incorrect_pred_incorrect_cluster*100/ (incorrect_pred_incorrect_cluster + incorrect_pred_correct_cluster)\n",
    "        # # print(f'{values} \\t\\t correct_flags: {correct_flags}, total_flags: {total_flags}, %correct: {recall:.2f}')\n",
    "        # return df, incorrect_pred_incorrect_cluster, incorrect_pred_incorrect_cluster + incorrect_pred_correct_cluster, recall\n",
    "\n",
    "    # print(f'Dataset: {dataset} \\t Attack: {atk} \\t Model: {model} \\t split: {split}')\n",
    "    # for r in [1,6,70,24,56,12,45,100]:\n",
    "        # print('############',r,'############')\n",
    "\n",
    "    # df = K_means_flagging(df,'norm_ddbs',r)\n",
    "    # df = K_means_flagging(df,'norm_Flipping_Freq',r)\n",
    "    if recall:\n",
    "        df, correct_flags, total_flags, flag_acc = K_means_flagging_recall(df,values,r)\n",
    "    else:\n",
    "        df, correct_flags, total_flags, flag_acc = K_means_flagging(df,values,r)\n",
    "    \n",
    "    return correct_flags, total_flags, flag_acc\n",
    "\n",
    "\n",
    "\n",
    "# errors,seeds = [],[]\n",
    "\n",
    "# for seed in tqdm(range(200)):\n",
    "#     correct_flags, total_flags, flag_acc_t = eval_t_score_model('vgg11','DeepFool', 120, seed=seed, values='T_score', verbose=False)\n",
    "#     correct_flags, total_flags, flag_acc_d = eval_t_score_model('vgg11','DeepFool', 120, seed=seed, values='norm_Flipping_Freq', verbose=False)\n",
    "\n",
    "#     errors.append(flag_acc_t - flag_acc_d)\n",
    "#     seeds.append(seed)\n",
    "# # print(f'T_Score \\t\\t correct_flags: {correct_flags}, total_flags: {total_flags}, %correct: {correct_flags*100/ total_flags:.2f}')\n",
    "# plt.figure(figsize=(40,3))\n",
    "# ax = sns.scatterplot(y=errors,x =seeds)\n",
    "# ax.set(xticks=seeds)\n",
    "# plt.show()\n",
    "\n",
    "# def cherrypick(errors):\n",
    "#     cherry_seed = np.argmax(np.array(errors))\n",
    "    \n",
    "#     correct_flags, total_flags, flag_acc_t = eval_t_score_model('vgg11','DeepFool', 120, seed=cherry_seed, values='T_score', verbose=False)\n",
    "#     correct_flags, total_flags, flag_acc_d = eval_t_score_model('vgg11','DeepFool', 120, seed=cherry_seed, values='norm_Flipping_Freq', verbose=False)\n",
    "\n",
    "\n",
    "#     print(f'flip_freq: {flag_acc_d} \\t t-score : {flag_acc_t}\\t cherry seed={cherry_seed}')\n",
    "#     return cherry_seed\n",
    "# cherry_seed = cherrypick(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eval_t_score_model() got an unexpected keyword argument 'recall'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-db77feec194f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'norm_ddbs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'norm_Flipping_Freq'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'T_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag_acc_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_t_score_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'robust_resnet18'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DeepFool'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# _,_, flag_acc_f = eval_t_score_model('mobilenet_freq','PGD', 120, seed=seed, values=val, verbose=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# _,_, flag_acc_t = eval_t_score_model('mobilenet_trust','PGD', 120, seed=seed, values=val, verbose=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: eval_t_score_model() got an unexpected keyword argument 'recall'"
     ]
    }
   ],
   "source": [
    "fl, db, ts,rn = [], [], [], [] # [resnet18, robust_resnet18, mobilenet_ddb, mobilenet_trust, robust_wideresnet, googlenet, vgg11]\n",
    "seed = 0 # PGD, DeepFool\n",
    "for val in ['norm_ddbs', 'norm_Flipping_Freq', 'T_score']:\n",
    "    \n",
    "    _,_, flag_acc_t = eval_t_score_model('robust_resnet18','DeepFool', seed=seed, values=val, verbose=False,recall=False)\n",
    "    # _,_, flag_acc_f = eval_t_score_model('mobilenet_freq','PGD', 120, seed=seed, values=val, verbose=False)\n",
    "    # _,_, flag_acc_t = eval_t_score_model('mobilenet_trust','PGD', 120, seed=seed, values=val, verbose=False)\n",
    "\n",
    "    # db.append(flag_acc_t)\n",
    "    # fl.append(flag_acc_f)\n",
    "    # ts.append(flag_acc_t)\n",
    "    # print(f'Metric {val}: flag_acc_trust : {flag_acc_t}\\t seed={seed}')\n",
    "\n",
    "# computed_val = pd.DataFrame({'Model ddb': db,'Model Flip freq': fl, 'Model Trust':ts},\n",
    "#                             index=['flag ddb', 'flag flip freq', 'flag trust']).T\n",
    "# computed_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f4c03fd1f3ddabab52b38077ff61d6f59c40ca8b7063d5b7a68c21aa3f2e988"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('rohit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
